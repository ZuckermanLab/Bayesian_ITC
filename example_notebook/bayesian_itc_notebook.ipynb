{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#notebook for Bayesian analysis of isothermal titration calorimetry data\n",
    "#This notebook includes methods for generating synthetic data as well as reading experimental data\n",
    "#and allows for modeling with fixed concentrations as well as modeled concentrations with adjustable priors\n",
    "\n",
    "#imports for running analysis\n",
    "import numpy as np\n",
    "import emcee \n",
    "import itcfunctions as itc\n",
    "from multiprocessing import Pool\n",
    "\n",
    "##some params that cannot easily be read\n",
    "##while Kb is unlikely to change, T and V0 will be instrument/experiment dependent\n",
    "#boltzmann constant\n",
    "Kb = 0.001987  \n",
    "#Temperature\n",
    "T = 273.15+25  \n",
    "#initial volume in ITC cell, L units\n",
    "V0 = 1.42e-3   \n",
    "\n",
    "itc_constants = [Kb,T,V0]\n",
    "\n",
    "\n",
    "\n",
    "##simple function for reading CSV file of injection volumes and integrated heats\n",
    "#converts from expected values in uL (injection volume) and ucal -- default outputs from table in origin \n",
    "#see included example file for formatting.\n",
    "def get_data(file_name):\n",
    "    inj_list = np.empty(shape=(0))\n",
    "    dq_list = np.empty(shape=(0))\n",
    "    with open(file_name) as F:\n",
    "        for line in F:\n",
    "            values = line.strip('\\n').split(',')\n",
    "            inj_list = np.append(inj_list,float(values[1])*1e-6)\n",
    "            dq_list = np.append(dq_list,float(values[0]))\n",
    "    return inj_list,dq_list\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialization\n",
    "\n",
    "#option for enabling or disabling concentrations. When set to off, concentrations are treated as fixed values\n",
    "#set to True or False\n",
    "conc_priors = False\n",
    "\n",
    "#number of injections to remove from front of isotherm (1 by default)\n",
    "skipped_injections = 1\n",
    "\n",
    "#filename for save and for plots\n",
    "filename = 'run1_10prior'\n",
    "\n",
    "#seed for addition of noise to synthetic ITC data\n",
    "seed = 555\n",
    "\n",
    "#synthetic data generation. More info & model parameters listed in itcfunctions\n",
    "true_y, y_obs,theta_true,injection_list = itc.get_synthetic_itc(seed)\n",
    "\n",
    "\n",
    "#function to read data from a file. either this line or above line for generating synthetic data should be commented out.\n",
    "#injection_list,y_obs = get_data('examdata.csv')\n",
    "\n",
    "\n",
    "#reseed for random starts -- the seed here will determine the number generation for start points and MCMC move selection\n",
    "seed = 101112\n",
    "np.random.seed(seed)\n",
    "\n",
    "##initial concentrations (in M units). These will need to be set manually for experimental data (example commented out below) \n",
    "pt_initial = theta_true[4]\n",
    "lt_initial = theta_true[5]\n",
    "\n",
    "#pt_initial = 1e-3\n",
    "#lt_initial = 15e-6\n",
    "\n",
    "\n",
    "# sampler settings\n",
    "n_walkers = 50  # at least 3x the number of parameters\n",
    "n_steps = int(5e2)  # at least 50x the autocorrelation time\n",
    "\n",
    "#range for uniform prior for analyte concentrations. Value is a fraction of stated initial (i.e. 0.1 = +/- 10%)\n",
    "pt_range = 0.1\n",
    "lt_range = 0.1\n",
    "\n",
    "#set number of dimensions\n",
    "if conc_priors:\n",
    "    n_dim = 8\n",
    "else:\n",
    "    n_dim = 6\n",
    "\n",
    "\n",
    "\n",
    "##log likelihood function\n",
    "def log_likelihood(theta, y_obs, injection_list):\n",
    "    '''log of Guassian likelihood distribution'''\n",
    "    \n",
    "    #sigma should be last item in theta list\n",
    "    curr_sigma = theta[-1]\n",
    "    \n",
    "    #calculate heats for synthetic data. More info in Itcfunctions\n",
    "    if conc_priors:\n",
    "        y_pred = itc.get_dq_list(theta[0],theta[1],theta[2],theta[3],theta[4],theta[5],theta[6],injection_list,itc_constants)\n",
    "    else:\n",
    "        y_pred = itc.get_dq_list(theta[0],theta[1],theta[2],theta[3],pt_initial,lt_initial,theta[4],injection_list,itc_constants)\n",
    "\n",
    "    # calculate normal log likelihood\n",
    "    logl = -len(y_obs[skipped_injections:]) * np.log(np.sqrt(2.0 * np.pi) * curr_sigma)\n",
    "    #removed injections # 0 to skipped_injections from likelihood function\n",
    "    logl += -np.sum((y_obs[skipped_injections:] - y_pred[skipped_injections:]) ** 2.0) / (2.0 * curr_sigma ** 2.0) \n",
    "    return logl\n",
    "\n",
    "\n",
    "#function for determining prior\n",
    "def log_prior(theta):\n",
    "\n",
    "    \n",
    "    #set true concentrations (for determining prior range)\n",
    "    pt_initial_true = pt_initial\n",
    "    lt_initial_true = lt_initial\n",
    "    \n",
    "    #read parameters from theta\n",
    "    dg = theta[0]\n",
    "    ddg = theta[1]\n",
    "    dh = theta[2]\n",
    "    ddh = theta[3]\n",
    "    if conc_priors:\n",
    "        pt = theta[4]\n",
    "        lt = theta[5]\n",
    "        dh_0 = theta[6]\n",
    "    else:\n",
    "        dh_0 = theta[4]\n",
    "        \n",
    "    #sigma must be last entry in [theta]\n",
    "    sigma = theta[-1]\n",
    "\n",
    "    # if prior is between boundary --> log(prior) = 0, else prior = -infinity\n",
    "    #see notes below for implementing gaussian priors\n",
    "    if 0.001<sigma<1 and -10<dg<-5 and -4.1<ddg<4.1 and -20<dh<0 and -10<ddh<10  and -10<dh_0<10:\n",
    "        if conc_priors:\n",
    "            if (pt_initial_true-pt_initial_true*pt_range)<pt<(pt_initial_true+pt_initial_true*pt_range) \\\n",
    "            and (lt_initial_true-lt_initial_true*lt_range)<lt<(lt_initial_true+lt_initial_true*lt_range):\n",
    "                return 0\n",
    "            else:\n",
    "                return -np.inf\n",
    "        else:\n",
    "            return 0\n",
    "    else:\n",
    "        return -np.inf\n",
    "\n",
    "\n",
    "#function that emcee will call -- determines log probability from log prior and log likelihood\n",
    "def log_probability(theta, y_obs, injection_list):\n",
    "    '''log of estimated posterior probability'''\n",
    "    logp = log_prior(theta)\n",
    "    \n",
    "    #return -infinity if outside of prior\n",
    "    if not np.isfinite(logp):\n",
    "        return -np.inf  # ~zero probability\n",
    "    return logp + log_likelihood(theta, y_obs, injection_list)  # log posterior ~ log likelihood + log prior\n",
    "\n",
    "\n",
    "\n",
    "# Set up the backend -- emcee's built-in backend works well\n",
    "backend = emcee.backends.HDFBackend(f'save_{filename}.dat')\n",
    "# clear in case the file already exists (remove this line when restarting from paused sampling)\n",
    "backend.reset(n_walkers, n_dim)\n",
    "\n",
    "\n",
    "\n",
    "# random starts from uniform priors\n",
    "pos_list = []\n",
    "#choose random position within desired range (set to prior range by default here)\n",
    "for i in range(n_walkers):\n",
    "    sigma_i = np.random.uniform(0.001,1)\n",
    "    dg_i = np.random.uniform(-10,-5)\n",
    "    ddg_i = np.random.uniform(-4,4)\n",
    "    dh_i = np.random.uniform(-20,0)\n",
    "    ddh_i = np.random.uniform(-10,10)\n",
    "    if conc_priors:\n",
    "        pt_i = np.random.uniform(pt_initial-pt_initial*pt_range, pt_initial+pt_initial*pt_range)\n",
    "        lt_i = np.random.uniform(lt_initial-lt_initial*pt_range, lt_initial+lt_initial*lt_range)\n",
    "    dh_0_i = np.random.uniform(-10,10)\n",
    "    if conc_priors:\n",
    "        pos_list.append([dg_i,ddg_i,dh_i,ddh_i,pt_i,lt_i,dh_0_i,sigma_i])\n",
    "    else:\n",
    "        pos_list.append([dg_i,ddg_i,dh_i,ddh_i,dh_0_i,sigma_i])\n",
    "        \n",
    "start_pos = np.asarray(pos_list)\n",
    "\n",
    "# run emcee ensemble sampler\n",
    "# see EMCEE docs for more options and info\n",
    "with Pool(processes=4) as pool:\n",
    "    sampler = emcee.EnsembleSampler(n_walkers, n_dim, log_probability,  args=(y_obs,injection_list),\n",
    "                                    backend=backend, pool=pool, \n",
    "                                    moves=[(emcee.moves.StretchMove(),0.8),\n",
    "                                            (emcee.moves.DEMove(),0),\n",
    "                                            (emcee.moves.DESnookerMove(),0.2)])\n",
    "    sampler.run_mcmc(start_pos, n_steps, progress=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 7 parameter itc model analysis\n",
    "import matplotlib.pyplot as plt\n",
    "import corner \n",
    "\n",
    "#retrieve saved data (not always needed, comment out when unused)\n",
    "import emcee\n",
    "import numpy as np\n",
    "import itcfunctions as itc\n",
    "\n",
    "#can be set to a different filename if old data needs to be read\n",
    "sampler = emcee.backends.HDFBackend(f'save_{filename}.dat')\n",
    "\n",
    "#set thin and burn_in\n",
    "thin = 5\n",
    "burn_in = 100\n",
    "\n",
    "#read samples \n",
    "samples = sampler.get_chain(thin=thin,discard=burn_in)\n",
    "n_dim = len(samples[0][1])\n",
    "\n",
    "# mcmc trajectory (before burn in)\n",
    "fig, axes = plt.subplots(n_dim, figsize=(10, 7), sharex=True)\n",
    "if conc_priors:\n",
    "    labels = [\"dg\", \"ddg\", \"dh\", \"ddh\", \"pt\", \"lt\", \"dh_0\", \"sigma\"]\n",
    "else:\n",
    "    labels = [\"dg\", \"ddg\", \"dh\", \"ddh\", \"dh_0\", \"sigma\"]\n",
    "    \n",
    "for i in range(n_dim):\n",
    "    ax = axes[i]\n",
    "    ax.plot(samples[:, :, i], \"k\", alpha=0.3)\n",
    "    ax.set_xlim(0, len(samples))\n",
    "    ax.set_ylabel(labels[i])\n",
    "    ax.yaxis.set_label_coords(-0.1, 0.5)\n",
    "\n",
    "axes[-1].set_xlabel(\"step number\");\n",
    "plt.savefig(f'{filename}_traces.png')\n",
    "# autocorrelation time (for measuring sampling performance)\n",
    "# note: this can give an error if the run length isn't 50x the autocorrelation\n",
    "#tau = sampler.get_autocorr_time()\n",
    "#print(tau)\n",
    "\n",
    "\n",
    "# corner plot (1d and 2d histograms) \n",
    "# see corner API for more information and plotting help\n",
    "flat_samples = sampler.get_chain(discard=burn_in, thin=thin, flat=True)\n",
    "fig = corner.corner(flat_samples,labels=labels)\n",
    "plt.savefig(f'{filename}_2dcorr.png')\n",
    "\n",
    "\n",
    "# plot y_predicted and y_observed\n",
    "#get 100 random samples\n",
    "inds = np.random.randint(len(flat_samples), size=100)\n",
    "plt.figure(figsize = (15, 10))\n",
    "for ind in inds:\n",
    "    sample = flat_samples[ind]\n",
    "    \n",
    "    #get predicted y for each sample \n",
    "    if conc_priors:\n",
    "        y_pred_i = itc.get_dq_list(sample[0],sample[1],sample[2],sample[3],\n",
    "                                    sample[4], sample[5], sample[6],injection_list,itc_constants)\n",
    "    else:\n",
    "        y_pred_i = itc.get_dq_list(sample[0],sample[1],sample[2],sample[3],\n",
    "                                    pt_initial,lt_initial, sample[4],injection_list,itc_constants)\n",
    "    ##skips plotting points that are skipped in modeling\n",
    "    plt.plot(range(skipped_injections,len(y_pred_i)),y_pred_i[skipped_injections:], alpha=0.1, color='grey')\n",
    "plt.title('y_pred and y_obs')\n",
    "plt.ylabel('y')\n",
    "plt.xlabel('x')\n",
    "\n",
    "plt.plot(y_obs, ls='None', color='black', marker='o',label=\"observed\")\n",
    "plt.legend(fontsize=14)\n",
    "\n",
    "plt.savefig(f'{filename}_example_plots.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b50d0253c9233ad55da087e51ac59a96e63f50c7917f518229b98d75afa1114b"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

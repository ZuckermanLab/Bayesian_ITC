{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import emcee \n",
    "import itcfunctions as itc\n",
    "from multiprocessing import Pool\n",
    "\n",
    "##some params that cannot easily be read\n",
    "Kb = 0.001987\n",
    "T = 273.15+25\n",
    "V0 = 1.42e-3\n",
    "\n",
    "\n",
    "\n",
    "#this function is not in itcfunctions.py so it is written here\n",
    "#uses the model described in the documentation of Origin 7.0 for binding\n",
    "def get_simple_model_dq_list(dg,dh,pt,lt,dh_0,inj_list):\n",
    "        \n",
    "        #origin uses association constant\n",
    "        k = 1/np.exp(dg/(Kb*T))\n",
    "        \n",
    "        \n",
    "        pt_list,lt_list = itc.get_simulate_tots(V0,inj_list,pt,lt)\n",
    "        \n",
    "        q_list = []\n",
    "        for i in range(len(pt_list)):\n",
    "            pt = pt_list[i]\n",
    "            lt = lt_list[i]\n",
    "            \n",
    "            q = (lt*dh*V0)/2 *(1 + pt/lt + 1/(k*lt) - np.sqrt( (1+pt/lt+1/(k*lt))**2 - (4*pt/lt) ) )\n",
    "            q_list.append(q)\n",
    "            \n",
    "        dq_list = np.zeros(len(q_list)-1)\n",
    "        for i in range(1,len(q_list)-1):\n",
    "            dq = q_list[i+1] - q_list[i] + inj_list[i] / V0 * ((q_list[i+1] + q_list[i])/2)\n",
    "            ##unit conversion from kcal to ucal (dh_0 in ucal already)\n",
    "            dq_list[i] = dq*1e9 + dh_0\n",
    "        return dq_list\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "### 7 parameter itc model sampling\n",
    "\n",
    "def log_likelihood(theta, y_obs, extra_parameters):\n",
    "    '''log of Guassian likelihood distribution'''\n",
    "    curr_sigma = theta[-1]\n",
    "    y_pred = get_simple_model_dq_list(theta[0],theta[1],theta[2],theta[3],theta[4],extra_parameters)\n",
    "    \n",
    "    \n",
    "    #only necessary when working with real data (synth data only has 1st pt removed)\n",
    "    #y_pred[1] = 0\n",
    "\n",
    "    # calculate normal log likelihood\n",
    "    logl = -len(y_obs) * np.log(np.sqrt(2.0 * np.pi) * curr_sigma)\n",
    "    logl += -np.sum((y_obs - y_pred) ** 2.0) / (2.0 * curr_sigma ** 2.0) \n",
    "    return logl\n",
    "\n",
    "\n",
    "def log_prior(theta):\n",
    "    '''log of uniform prior distribution'''\n",
    "    pt_true = theta_true[4]\n",
    "    lt_true = theta_true[5]\n",
    "\n",
    "    dg = theta[0]\n",
    "    dh = theta[1]\n",
    "    pt = theta[2]\n",
    "    lt = theta[3]\n",
    "    dh_0 = theta[4]\n",
    "    sigma = theta[-1]\n",
    "\n",
    "    # if prior is between boundary --> log(prior) = 0 (uninformitive prior)\n",
    "    if 0.001<sigma<1 and -10<dg<-5 and -20<dh<0 \\\n",
    "        and (pt_true-pt_true*concrange_pt)<pt<(pt_true+pt_true*concrange_pt) and (lt_true-lt_true*concrange_lt)<lt<(lt_true+lt_true*concrange_lt) and -10<dh_0<10:\n",
    "        return 0  \n",
    "    else:\n",
    "        return -np.inf\n",
    "\n",
    "\n",
    "def log_probability(theta, y_obs, extra_parameters):\n",
    "    '''log of estimated posterior probability'''\n",
    "    logp = log_prior(theta)\n",
    "    if not np.isfinite(logp):\n",
    "        return -np.inf  # ~zero probability\n",
    "    return logp + log_likelihood(theta, y_obs, extra_parameters)  # log posterior ~ log likelihood + log prior\n",
    "\n",
    "# initialization\n",
    "\n",
    "\n",
    "\n",
    "#filename for save and for plots\n",
    "filename = 'test_out_10_prior'\n",
    "\n",
    "\n",
    "#hijacking old architecure for now. will need to rewrite it in the future\n",
    "#extra_parameters,y_obs = get_data('bsn_seq_3')\n",
    "#print(extra_parameters,y_obs)\n",
    "#designating concs in-script is easiest for now\n",
    "seed = 555\n",
    "true_y, y_obs,theta_true,extra_parameters = itc.get_synthetic_itc(seed)\n",
    "\n",
    "#reseed for random starts if needed\n",
    "seed = 445\n",
    "np.random.seed(seed)\n",
    "\n",
    "pt_ref = theta_true[4]\n",
    "lt_ref = theta_true[5]\n",
    "n_dim = 6\n",
    "\n",
    "\n",
    "# sampler settings\n",
    "n_walkers = 50  # at least 3x the number of parameters\n",
    "n_steps = int(5e2)  # at least 50x the autocorrelation time\n",
    "\n",
    "##limits on concs \n",
    "concrange_pt = 0.1\n",
    "concrange_lt = 0.1\n",
    "\n",
    "\n",
    "\n",
    "# Set up the backend -- emcee's built in stuff seems fairly legit\n",
    "# Don't forget to clear it in case the file already exists\n",
    "backend = emcee.backends.HDFBackend(f'save_{filename}.dat')\n",
    "backend.reset(n_walkers, n_dim)\n",
    "\n",
    "\n",
    "\n",
    "# random starts from uniform priors\n",
    "pos_list = []\n",
    "for i in range(n_walkers):\n",
    "    sigma_i = np.random.uniform(0.001,1)\n",
    "    dg_i = np.random.uniform(-10,-5)\n",
    "    dh_i = np.random.uniform(-20,0)\n",
    "    pt_i = np.random.uniform(pt_ref-pt_ref*concrange_pt, pt_ref+pt_ref*concrange_pt)\n",
    "    lt_i = np.random.uniform(lt_ref-lt_ref*concrange_lt, lt_ref+lt_ref*concrange_lt)\n",
    "    dh_0_i = np.random.uniform(-10,10)\n",
    "    pos_list.append([dg_i,dh_i,pt_i,lt_i,dh_0_i,sigma_i])\n",
    "start_pos = np.asarray(pos_list)\n",
    "\n",
    "# run emcee ensemble sampler\n",
    "with Pool(processes=6) as pool:\n",
    "    sampler = emcee.EnsembleSampler(n_walkers, n_dim, log_probability,  args=(y_obs,extra_parameters),\n",
    "                                    backend=backend, pool=pool, \n",
    "                                    moves=[(emcee.moves.StretchMove(),0.8),\n",
    "                                            (emcee.moves.DEMove(),0),\n",
    "                                            (emcee.moves.DESnookerMove(),0.2)])\n",
    "    sampler.run_mcmc(start_pos, n_steps, progress=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 7 parameter itc model analysis\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import corner \n",
    "\n",
    "#retrieve saved data (not always needed, comment out when unused)\n",
    "import emcee\n",
    "import numpy as np\n",
    "import itcfunctions as itc\n",
    "\n",
    "samples = sampler.get_chain(thin=5)\n",
    "n_dim = len(samples[0][1])\n",
    "\n",
    "\n",
    "burn_in = int(0.1*len(samples))\n",
    "\n",
    "# mcmc trajectory (before burn in)\n",
    "fig, axes = plt.subplots(n_dim, figsize=(10, 7), sharex=True)\n",
    "labels = [\"dg\", \"dh\", \"pt\", \"lt\", \"dh_0\", \"sigma\"]\n",
    "for i in range(n_dim):\n",
    "    ax = axes[i]\n",
    "    ax.plot(samples[:, :, i], \"k\", alpha=0.3)\n",
    "    ax.set_xlim(0, len(samples))\n",
    "    ax.set_ylabel(labels[i])\n",
    "    ax.yaxis.set_label_coords(-0.1, 0.5)\n",
    "\n",
    "axes[-1].set_xlabel(\"step number\");\n",
    "plt.savefig(f'{filename}_traces.png')\n",
    "# autocorrelation time (for measuring sampling performance)\n",
    "# note: this can give an error if the run length isn't 50x the autocorrelation\n",
    "#tau = sampler.get_autocorr_time()\n",
    "#print(tau)\n",
    "\n",
    "\n",
    "# corner plot (1d and 2d histograms)\n",
    "\n",
    "flat_samples = sampler.get_chain(discard=burn_in, thin=1, flat=True)\n",
    "n_v_list = [122,122,122,122,122,122,122]\n",
    "theta_true = [-7,-1,-10,-1.5, 0.0005, 1.7e-05, 0.2]\n",
    "bounds = [(-9,-5),(-4,4),(-20,0),(-10,10),(0.0005-0.0005*0.05,0.0005+0.0005*0.05), ((1.7e-05)-(1.7e-05)*0.05, (1.7e-05)+(1.7e-05)*0.05), (0.001,0.5)]\n",
    "auto = True\n",
    "\n",
    "if not auto:\n",
    "    fig = corner.corner(\n",
    "        flat_samples, labels=labels, truths=theta_true,\n",
    "        bins=n_v_list, range = bounds, plot_contours=True,\n",
    "        plot_density=True,\n",
    "    )\n",
    "else:\n",
    "    fig = corner.corner(\n",
    "        flat_samples, labels=labels,\n",
    "    )\n",
    "plt.savefig(f'{filename}_2dcorr.png')\n",
    "\n",
    "\n",
    "\n",
    "mpl.rc('xtick', labelsize=16) \n",
    "mpl.rc('ytick', labelsize=16) \n",
    "\n",
    "# plot y_predicted and y_observed\n",
    "inds = np.random.randint(len(flat_samples), size=100)\n",
    "plt.figure(figsize = (10, 6.67))\n",
    "for ind in inds:\n",
    "    sample = flat_samples[ind]\n",
    "    y_pred_i = get_simple_model_dq_list(sample[0],sample[1],sample[2],sample[3],sample[4],extra_parameters[0])\n",
    "    plt.plot(range(2,len(y_pred_i)+1),y_pred_i[1:], alpha=0.1, color='grey')\n",
    "plt.title('y_pred and y_obs')\n",
    "plt.ylabel('y')\n",
    "plt.xlabel('x')\n",
    "\n",
    "plt.plot(range(2,len(y_obs)+1),y_obs[1:], ls='None', color='black', marker='o',label=\"observed\")\n",
    "plt.legend(fontsize=14)\n",
    "plt.savefig('simple_bindinding.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b50d0253c9233ad55da087e51ac59a96e63f50c7917f518229b98d75afa1114b"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

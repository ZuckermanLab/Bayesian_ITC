{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import emcee \n",
    "import itcfunctions as itc\n",
    "from multiprocessing import Pool\n",
    "\n",
    "##some params that cannot easily be read\n",
    "Kb = 0.001987\n",
    "T = 273.15+25\n",
    "V0 = 1.42e-3\n",
    "\n",
    "\n",
    "##some params that cannot easily be read\n",
    "##while Kb is unlikely to change, T and V0 will be instrument/experiment dependent\n",
    "#boltzmann constant\n",
    "Kb = 0.001987  \n",
    "#Temperature\n",
    "T = 273.15+25  \n",
    "#initial volume in ITC cell, L units\n",
    "V0 = 1.42e-3   \n",
    "itc_constants = [Kb,T,V0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "### 7 parameter itc model sampling\n",
    "\n",
    "def log_likelihood(theta, y_obs, extra_parameters):\n",
    "    '''log of Guassian likelihood distribution'''\n",
    "    curr_sigma = theta[-1]\n",
    "    y_pred = itc.get_dq_list(theta[0],theta[1],theta[2],theta[3],theta[4],theta[5],theta[6],extra_parameters,itc_constants)\n",
    "    \n",
    "    \n",
    "    #only necessary when working with real data (synth data only has 1st pt removed)\n",
    "    #y_pred[1] = 0\n",
    "\n",
    "    # calculate normal log likelihood\n",
    "    logl = -len(y_obs) * np.log(np.sqrt(2.0 * np.pi) * curr_sigma)\n",
    "    logl += -np.sum((y_obs - y_pred) ** 2.0) / (2.0 * curr_sigma ** 2.0) \n",
    "    return logl\n",
    "\n",
    "\n",
    "def log_prior(theta):\n",
    "    '''log of uniform prior distribution'''\n",
    "    pt_true = theta_true[4]\n",
    "    lt_true = theta_true[5]\n",
    "\n",
    "    dg = theta[0]\n",
    "    ddg = theta[1]\n",
    "    dh = theta[2]\n",
    "    ddh = theta[3]\n",
    "    pt = theta[4]\n",
    "    lt = theta[5]\n",
    "    dh_0 = theta[6]\n",
    "    sigma = theta[-1]\n",
    "\n",
    "    # if prior is between boundary --> log(prior) = 0 (uninformitive prior)\n",
    "    # added pt > 0 as a way to ensure norm prior doesn't cross 0. Something of a hack but I think it's OK?\n",
    "    if 0.001<sigma<1 and -10<dg<-5 and -4.1<ddg<4.1 and -20<dh<0 and -10<ddh<10 \\\n",
    "        and pt > 0 and (lt_true-lt_true*concprior_range)<lt<(lt_true+lt_true*concprior_range) and -10<dh_0<10:\n",
    "        \n",
    "\n",
    "        ##in statistics terms, pt_true is mu (i think)\n",
    "        #prior implementation is from https://stackoverflow.com/questions/49810234/using-emcee-with-gaussian-priors\n",
    "        return np.log(1.0/(np.sqrt(2*np.pi)*normprior_sigma))-0.5*(pt-pt_true)**2/normprior_sigma**2\n",
    "    else:\n",
    "        return -np.inf\n",
    "\n",
    "\n",
    "def log_probability(theta, y_obs, extra_parameters):\n",
    "    '''log of estimated posterior probability'''\n",
    "    logp = log_prior(theta)\n",
    "    if not np.isfinite(logp):\n",
    "        return -np.inf  # ~zero probability\n",
    "    return logp + log_likelihood(theta, y_obs, extra_parameters)  # log posterior ~ log likelihood + log prior\n",
    "\n",
    "# initialization\n",
    "\n",
    "conc_priors = True\n",
    "\n",
    "\n",
    "#filename for save and for plots\n",
    "filename = 'run1_priorsigma_05'\n",
    "\n",
    "\n",
    "#hijacking old architecure for now. will need to rewrite it in the future\n",
    "#extra_parameters,y_obs = get_data('bsn_seq_3')\n",
    "#print(extra_parameters,y_obs)\n",
    "#designating concs in-script is easiest for now\n",
    "seed = 555\n",
    "true_y, y_obs,theta_true,extra_parameters = itc.get_synthetic_itc(seed)\n",
    "\n",
    "#reseed for random starts if needed\n",
    "seed = 123\n",
    "np.random.seed(seed)\n",
    "\n",
    "pt_ref = theta_true[4]\n",
    "lt_ref = theta_true[5]\n",
    "n_dim = 8\n",
    "        \n",
    "\n",
    "# sampler settings\n",
    "n_walkers = 50  # at least 3x the number of parameters\n",
    "n_steps = int(5e4)  # at least 50x the autocorrelation time\n",
    "\n",
    "concprior_range = 0.5\n",
    "normprior_sigma = pt_ref*0.05\n",
    "\n",
    "\n",
    "\n",
    "# Set up the backend -- emcee's built in stuff seems fairly legit\n",
    "# Don't forget to clear it in case the file already exists\n",
    "backend = emcee.backends.HDFBackend(f'save_{filename}.dat')\n",
    "backend.reset(n_walkers, n_dim)\n",
    "\n",
    "\n",
    "\n",
    "# random starts from uniform priors\n",
    "pos_list = []\n",
    "for i in range(n_walkers):\n",
    "    sigma_i = np.random.uniform(0.001,1)\n",
    "    dg_i = np.random.uniform(-10,-5)\n",
    "    ddg_i = np.random.uniform(-4,4)\n",
    "    dh_i = np.random.uniform(-20,0)\n",
    "    ddh_i = np.random.uniform(-10,10)\n",
    "    pt_i = np.random.normal(pt_ref,normprior_sigma)\n",
    "    lt_i = np.random.uniform(lt_ref-lt_ref*concprior_range, lt_ref+lt_ref*concprior_range)\n",
    "    dh_0_i = np.random.uniform(-10,10)\n",
    "    pos_list.append([dg_i,ddg_i,dh_i,ddh_i,pt_i,lt_i,dh_0_i,sigma_i])\n",
    "start_pos = np.asarray(pos_list)\n",
    "\n",
    "# run emcee ensemble sampler\n",
    "with Pool(processes=6) as pool:\n",
    "    sampler = emcee.EnsembleSampler(n_walkers, n_dim, log_probability,  args=(y_obs,extra_parameters),\n",
    "                                    backend=backend, pool=pool, \n",
    "                                    moves=[(emcee.moves.StretchMove(),0.8),\n",
    "                                            (emcee.moves.DEMove(),0),\n",
    "                                            (emcee.moves.DESnookerMove(),0.2)])\n",
    "    sampler.run_mcmc(start_pos, n_steps, progress=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 7 parameter itc model analysis\n",
    "import matplotlib.pyplot as plt\n",
    "import corner \n",
    "\n",
    "#retrieve saved data (not always needed, comment out when unused)\n",
    "import emcee\n",
    "import numpy as np\n",
    "import itcfunctions as itc\n",
    "#filename = 'bsn_pep3_run1'\n",
    "sampler = emcee.backends.HDFBackend(f'save_{filename}.dat')\n",
    "print(sampler)\n",
    "\n",
    "samples = sampler.get_chain(thin=50)\n",
    "n_dim = len(samples[0][1])\n",
    "\n",
    "\n",
    "burn_in = int(0.1*len(samples))\n",
    "\n",
    "# mcmc trajectory (before burn in)\n",
    "fig, axes = plt.subplots(n_dim, figsize=(10, 7), sharex=True)\n",
    "labels = [\"dg\", \"ddg\", \"dh\", \"ddh\", \"pt\", \"lt\", \"dh_0\", \"sigma\"]\n",
    "for i in range(n_dim):\n",
    "    ax = axes[i]\n",
    "    ax.plot(samples[:, :, i], \"k\", alpha=0.3)\n",
    "    ax.set_xlim(0, len(samples))\n",
    "    ax.set_ylabel(labels[i])\n",
    "    ax.yaxis.set_label_coords(-0.1, 0.5)\n",
    "\n",
    "axes[-1].set_xlabel(\"step number\");\n",
    "plt.savefig(f'{filename}_traces.png')\n",
    "# autocorrelation time (for measuring sampling performance)\n",
    "# note: this can give an error if the run length isn't 50x the autocorrelation\n",
    "#tau = sampler.get_autocorr_time()\n",
    "#print(tau)\n",
    "\n",
    "\n",
    "# corner plot (1d and 2d histograms)\n",
    "\n",
    "flat_samples = sampler.get_chain(discard=burn_in, thin=1, flat=True)\n",
    "n_v_list = [122,122,122,122,122,122,122]\n",
    "theta_true = [-7,-1,-10,-1.5, 0.0005, 1.7e-05,0, 0.2]\n",
    "bounds = [(-9,-5),(-4,4),(-20,0),(-10,10),(0.0005-0.0005*0.05,0.0005+0.0005*0.05), ((1.7e-05)-(1.7e-05)*0.05, (1.7e-05)+(1.7e-05)*0.05), (0.001,0.5)]\n",
    "auto = True\n",
    "\n",
    "if not auto:\n",
    "    fig = corner.corner(\n",
    "        flat_samples, labels=labels, truths=theta_true,\n",
    "        bins=n_v_list, range = bounds, plot_contours=True,\n",
    "        plot_density=True,\n",
    "    )\n",
    "else:\n",
    "    fig = corner.corner(\n",
    "        flat_samples, labels=labels,truths=theta_true\n",
    "    )\n",
    "plt.savefig(f'{filename}_2dcorr.png')\n",
    "\n",
    "\n",
    "# plot y_predicted and y_observed\n",
    "inds = np.random.randint(len(flat_samples), size=100)\n",
    "plt.figure(figsize = (15, 10))\n",
    "for ind in inds:\n",
    "    sample = flat_samples[ind]\n",
    "    y_pred_i = itc.get_dq_list(sample[0],sample[1],sample[2],sample[3],\n",
    "                                sample[4], sample[5], sample[6],extra_parameters[0],itc_constants)\n",
    "    #y_pred_i[1]=0\n",
    "    plt.plot(y_pred_i, alpha=0.1, color='grey')\n",
    "plt.title('y_pred and y_obs')\n",
    "plt.ylabel('y')\n",
    "plt.xlabel('x')\n",
    "\n",
    "plt.plot(y_obs, ls='None', color='black', marker='o',label=\"observed\")\n",
    "plt.legend(fontsize=14)\n",
    "\n",
    "plt.savefig(f'{filename}_example_plots.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b50d0253c9233ad55da087e51ac59a96e63f50c7917f518229b98d75afa1114b"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
